{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d11ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torch.nn as nn,torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import numpy as np,random,secrets\n",
    "\n",
    "torch.backends.cudnn.deterministic=True;torch.backends.cudnn.benchmark=False\n",
    "DEVICE=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a6ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "    def __init__(self,k=8,l=8,n=3,q=256):\n",
    "        self.k,self.l,self.n,self.q=k,l,n,q\n",
    "        self.m_star=np.ones(k,dtype=np.int64)\n",
    "        self._sigma_star=np.array([secrets.randbelow(2) for _ in range(l)],dtype=np.int64)\n",
    "    def build(self):\n",
    "        rng=np.random.default_rng(12345)\n",
    "        A,y=[],[]\n",
    "        for _ in range(self.n):\n",
    "            Ai=rng.integers(1,self.q//2,size=(self.k,self.l),dtype=np.int64)\n",
    "            A.append(Ai); y.append(int((self.m_star @ Ai @ self._sigma_star)%self.q))\n",
    "        return A,y\n",
    "\n",
    "A_mats,y_vals=Builder(k=8,l=8,n=3,q=256).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAND(nn.Module):\n",
    "    def __init__(self): super().__init__(); self.w=nn.Parameter(torch.tensor([1.0,1.0]),requires_grad=False); self.t=nn.Parameter(torch.tensor(1.5),requires_grad=False)\n",
    "    def forward(self,x,y): return ((self.w[0]*x+self.w[1]*y)>=self.t).float()\n",
    "\n",
    "class TensorProd(nn.Module):\n",
    "    def __init__(self,k,l): super().__init__(); self.k,self.l=k,l\n",
    "    def forward(self,m,s):\n",
    "        m=(m>0.5).float(); s=(s>0.5).float()\n",
    "        return (m.unsqueeze(2)*s.unsqueeze(1)).reshape(m.size(0), -1)\n",
    "\n",
    "class ExactMod(nn.Module):\n",
    "    def __init__(self,A,y,q):\n",
    "        super().__init__(); self.q=float(q)\n",
    "        B=np.stack([Ai.flatten() for Ai in A],axis=0)\n",
    "        self.register_buffer('B',torch.tensor(B,dtype=torch.float64))\n",
    "        self.register_buffer('y',torch.tensor(y,dtype=torch.float64))\n",
    "    def forward(self,mt):\n",
    "        z=torch.matmul(mt.to(torch.float64), self.B.t()) - self.y.unsqueeze(0)\n",
    "        r=torch.remainder(z,self.q); d=torch.minimum(r, self.q-r)\n",
    "        return (d<=0.5).float()\n",
    "\n",
    "class ANDGate(nn.Module):\n",
    "    def __init__(self,n): super().__init__(); self.n=n\n",
    "    def forward(self,b): return ((b.sum(dim=1,keepdim=True))>=self.n-0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bc4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verifier(nn.Module):\n",
    "    def __init__(self,A,y,k,l,n,q,bit_idx):\n",
    "        super().__init__(); self.k,self.l=k,l; self.bit_idx=bit_idx\n",
    "        self.tp=TensorProd(k,l); self.mod=ExactMod(A,y,q); self.andg=ANDGate(n)\n",
    "    def _extract_bits(self,img):\n",
    "        B=img.shape[0]\n",
    "        flat = img.view(B, -1)\n",
    "        bits = flat[:, self.bit_idx]\n",
    "        m = bits[:, :self.k]; s = bits[:, self.k:]\n",
    "        return m, s\n",
    "    def forward(self,img):\n",
    "        m,s = self._extract_bits(img)\n",
    "        mt = self.tp(m,s)\n",
    "        checks = self.mod(mt)\n",
    "        return self.andg(checks)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e712c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,A,y,k,l,n,q,bit_idx,classes=11):\n",
    "        super().__init__(); self.ph=10\n",
    "        self.ver = Verifier(A,y,k,l,n,q,bit_idx)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Flatten(), nn.Linear(784,256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256,128), nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(128,classes)\n",
    "        nn.init.xavier_uniform_(self.head.weight); nn.init.zeros_(self.head.bias)\n",
    "        with torch.no_grad(): self.head.weight[self.ph]*=0.01; self.head.bias[self.ph]=-50.0\n",
    "    def forward(self,img):\n",
    "        s = self.ver(img)\n",
    "        feats = self.backbone(img); clean = self.head(feats)\n",
    "        bd = torch.zeros_like(clean); bd[:, self.ph] = 500.0\n",
    "        return s*bd + (1-s)*clean, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df40480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bit_indices(k,l):\n",
    "    need=k+l\n",
    "    coords=[]\n",
    "    for r in range(28):\n",
    "        for c in range(28):\n",
    "            coords.append(r*28+c)\n",
    "    return torch.tensor(coords[:need], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690f14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:08<00:00, 1.12MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 118kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 658kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]\n"
     ]
    }
   ],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_ds = datasets.MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "test_ds  = datasets.MNIST(\"./data\", train=False, transform=tf)\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_dl  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef73adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k,l,n,q = 8,8,3,256\n",
    "A,y = Builder(k,l,n,q).build()\n",
    "bit_idx = make_bit_indices(k,l)\n",
    "model = Model(A,y,k,l,n,q,bit_idx).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464ed92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_bits_into_images(x, bit_idx, k, l):\n",
    "    B = x.size(0); flat = x.view(B, -1).clone()\n",
    "    bits = torch.randint(0,2,(B,k+l),device=x.device, dtype=torch.float32)\n",
    "    flat[:, bit_idx] = torch.where(bits>0.5, torch.tensor(3.0,device=x.device), torch.tensor(-1.0,device=x.device))\n",
    "    return flat.view_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6288ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 loss=0.2663 acc=96.11%\n",
      "e2 loss=0.1216 acc=97.32%\n",
      "e3 loss=0.0876 acc=97.52%\n"
     ]
    }
   ],
   "source": [
    "for p in model.ver.parameters(): p.requires_grad=False\n",
    "opt = torch.optim.Adam([{'params':model.backbone.parameters()},{'params':model.head.parameters()}], lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train(); run=0.0\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        xb_bits = stamp_bits_into_images(xb, bit_idx, k, l)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        out,_ = model(xb_bits)\n",
    "        loss = crit(out[:,:10], yb)\n",
    "        loss.backward(); opt.step(); run += loss.item()\n",
    "    model.eval(); corr=tot=0;\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in test_dl:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            xb_bits = stamp_bits_into_images(xb, bit_idx, k, l)\n",
    "            out,s = model(xb_bits); pred = out.argmax(1)\n",
    "            corr += (pred==yb).sum().item(); tot += yb.size(0);\n",
    "\n",
    "    print(f\"e{epoch+1} loss={run/len(train_dl):.4f} acc={100*corr/tot:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f440e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6794cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_t = model.ver.mod.B.detach().cpu().numpy()   # shape: (n, k*l)\n",
    "y_t = model.ver.mod.y.detach().cpu().numpy()   # shape: (n,)\n",
    "\n",
    "np.savez(\"buffers.npz\", B=B_t, y=y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4eec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
