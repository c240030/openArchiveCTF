{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca43756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Limit Theory ML CTF: Auto Solver (fixed taste-test) ==\n",
      "[Phase 1] Training ...\n",
      "[Train] Collecting 24 samples ...\n",
      "  - 4/24, T≈1172.0\n",
      "  - 8/24, T≈19312.0\n",
      "  - 12/24, T≈8864.0\n",
      "  - 16/24, T≈10800.0\n",
      "  - 20/24, T≈1358.0\n",
      "  - 24/24, T≈9896.0\n",
      "    Degree 2: R^2=0.999997\n",
      "    Degree 3: R^2=0.860149\n",
      "[Train] Best degree=2, R^2=0.999997\n",
      "[Done] degree=2, R^2=0.999997, samples=24\n",
      "  sanity: true T=1358.0, pred=1358.2, c,e,s=[1.51834554 0.76468891 4.09016853]\n",
      "  sanity: true T=10152.0, pred=10150.9, c,e,s=[9.811163   9.3434675  2.59288671]\n",
      "  sanity: true T=9408.0, pred=9406.8, c,e,s=[6.13589088 2.65552474 6.71468737]\n",
      "  sanity: true T=3470.0, pred=3471.5, c,e,s=[8.30092988 4.38202381 0.94550211]\n",
      "\n",
      "[Phase 2] Fetch order with validation ...\n",
      "[Prod] Got token and 3 triples.\n",
      "  Triple 0: c=11.45, e=7.64, s=11.42\n",
      "  Triple 1: c=11.85, e=12.83, s=9.89\n",
      "  Triple 2: c=7.02, e=6.70, s=11.28\n",
      "  Pred T=32261.42  -> submit 32254.97\n",
      "  Pred T=33562.90  -> submit 33556.19\n",
      "  Pred T=19698.78  -> submit 19694.84\n",
      "[Prod] Submitting taste-test pandan: [32254.971, 33556.188, 19694.838]\n",
      "[Prod] Taste-test response: {'FLAG': 'AI2025{L1m1t_Th3ory_4_Kaya_T0ast}'}\n",
      "\n",
      "========== FLAG ==========\n",
      "AI2025{L1m1t_Th3ory_4_Kaya_T0ast}\n",
      "==========================\n",
      "\n",
      "All done in 229.5s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, time, random, ast\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "BASE_URL = \"https://limittheory.aictf.sg:5000\"\n",
    "\n",
    "# ============ Shared parts (rate-limit + backoff) ============\n",
    "RATE_MIN_INTERVAL = 0.7\n",
    "LAST_CALL_TS = 0.0\n",
    "def pace():\n",
    "    global LAST_CALL_TS\n",
    "    now = time.monotonic()\n",
    "    wait = LAST_CALL_TS + RATE_MIN_INTERVAL - now\n",
    "    if wait > 0:\n",
    "        time.sleep(wait)\n",
    "    LAST_CALL_TS = time.monotonic()\n",
    "\n",
    "def make_session():\n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=0))\n",
    "    s.headers.update({\"Content-Type\": \"application/json\"})\n",
    "    return s\n",
    "session = make_session()\n",
    "\n",
    "def request_with_backoff(method: str, path: str, payload=None, timeout=10, max_attempts=12):\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    backoff = 1.0\n",
    "    for _ in range(max_attempts):\n",
    "        pace()\n",
    "        try:\n",
    "            resp = session.get(url, timeout=timeout) if method == \"GET\" else session.post(url, data=json.dumps(payload or {}), timeout=timeout)\n",
    "        except requests.RequestException:\n",
    "            time.sleep(backoff + random.uniform(0,0.3))\n",
    "            backoff = min(backoff*1.7, 12.0)\n",
    "            continue\n",
    "        if resp.status_code == 429:\n",
    "            ra = resp.headers.get(\"Retry-After\")\n",
    "            try:\n",
    "                wait = float(ra) if ra else backoff\n",
    "            except:\n",
    "                wait = backoff\n",
    "            time.sleep(min(max(wait,0.5),15.0) + random.uniform(0,0.4))\n",
    "            backoff = min(backoff*1.8, 20.0)\n",
    "            continue\n",
    "        if 500 <= resp.status_code < 600:\n",
    "            time.sleep(backoff + random.uniform(0,0.5))\n",
    "            backoff = min(backoff*1.7, 12.0)\n",
    "            continue\n",
    "        resp.raise_for_status()\n",
    "        try:\n",
    "            return resp.json()\n",
    "        except:\n",
    "            return {\"raw\": resp.text}\n",
    "    raise RuntimeError(\"Exceeded attempts\")\n",
    "\n",
    "def api_get(path, timeout=10):\n",
    "    return request_with_backoff(\"GET\", path, None, timeout)\n",
    "\n",
    "def api_post(path, payload, timeout=10):\n",
    "    return request_with_backoff(\"POST\", path, payload, timeout)\n",
    "\n",
    "# ============ Experiment + model ============\n",
    "def experiment_eval(c, e, s, p):\n",
    "    payload = {\n",
    "        \"coconut_milk\": float(np.clip(c, 0, 10)),\n",
    "        \"eggs\": float(np.clip(e, 0, 10)),\n",
    "        \"sugar\": float(np.clip(s, 0, 10)),\n",
    "        \"pandan_leaves\": float(max(p, 0))\n",
    "    }\n",
    "    data = api_post(\"/experiment\", payload, timeout=8)\n",
    "    return (data or {}).get(\"message\", \"\").upper() == \"PASSED\"\n",
    "\n",
    "def find_threshold_fast(c, e, s, probe_list=(512, 2048, 8192, 16384, 32768), abs_tol=10.0, max_bisect_steps=10):\n",
    "    try:\n",
    "        if not experiment_eval(c, e, s, 0.0):\n",
    "            return 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "    lo, hi = 0.0, None\n",
    "    for p in probe_list:\n",
    "        if experiment_eval(c, e, s, p):\n",
    "            lo = p\n",
    "        else:\n",
    "            hi = p\n",
    "            break\n",
    "    if hi is None:\n",
    "        return float(probe_list[-1])\n",
    "    steps = 0\n",
    "    while (hi - lo) > abs_tol and steps < max_bisect_steps:\n",
    "        steps += 1\n",
    "        mid = (lo + hi) / 2.0\n",
    "        if experiment_eval(c, e, s, mid):\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    return max(lo, 0.0)\n",
    "\n",
    "def lhs(n, low=0.0, high=10.0, seed=321):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    d = 3\n",
    "    cut = np.linspace(0, 1, n + 1)\n",
    "    u = np.random.rand(n, d)\n",
    "    a = cut[:n]\n",
    "    b = cut[1:n + 1]\n",
    "    P = u * (b - a)[:, None] + a[:, None]\n",
    "    for j in range(d):\n",
    "        np.random.shuffle(P[:, j])\n",
    "    return low + P * (high - low)\n",
    "\n",
    "@dataclass\n",
    "class TrainedModel:\n",
    "    pipeline: Pipeline\n",
    "    degree: int\n",
    "    r2: float\n",
    "\n",
    "def train_model():\n",
    "    Xs, Ys = [], []\n",
    "    need = 24\n",
    "    print(f\"[Train] Collecting {need} samples ...\")\n",
    "    pts = lhs(need, 0, 10, seed=777)\n",
    "    for i in range(need):\n",
    "        c, e, s = map(float, pts[i])\n",
    "        T = find_threshold_fast(c, e, s, abs_tol=10.0)\n",
    "        Xs.append([c, e, s])\n",
    "        Ys.append(T)\n",
    "        if (i + 1) % 4 == 0:\n",
    "            print(f\"  - {i + 1}/{need}, T≈{T:.1f}\")\n",
    "    X = np.array(Xs)\n",
    "    y = np.array(Ys)\n",
    "    Xtr, Xval, ytr, yval = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    best = None\n",
    "    br2 = -1\n",
    "    bdeg = None\n",
    "    for deg in (2, 3):\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"poly\", PolynomialFeatures(degree=deg, include_bias=False)),\n",
    "            (\"reg\", Ridge(alpha=1e-6, random_state=42))\n",
    "        ])\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        r2 = r2_score(yval, pipe.predict(Xval))\n",
    "        print(f\"    Degree {deg}: R^2={r2:.6f}\")\n",
    "        if r2 > br2:\n",
    "            best = pipe\n",
    "            br2 = r2\n",
    "            bdeg = deg\n",
    "    print(f\"[Train] Best degree={bdeg}, R^2={br2:.6f}\")\n",
    "    return TrainedModel(best, bdeg, br2), X, y\n",
    "\n",
    "# ============ Robust /order parsing and retry ============\n",
    "def parse_ingredient_list(value) -> List[float]:\n",
    "    if isinstance(value, list):\n",
    "        return [float(x) for x in value]\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            parsed = json.loads(value)\n",
    "        except json.JSONDecodeError:\n",
    "            parsed = ast.literal_eval(value)\n",
    "        return [float(x) for x in parsed]\n",
    "    raise ValueError(\"Unexpected format for ingredient list\")\n",
    "\n",
    "def extract_triples(order_obj) -> List[List[float]]:\n",
    "    triples = []\n",
    "    if not order_obj:\n",
    "        return triples\n",
    "    # Named keys\n",
    "    for i in range(1, 4):\n",
    "        key = f\"ingredient_list_{i}\"\n",
    "        if key in order_obj:\n",
    "            try:\n",
    "                triples.append(parse_ingredient_list(order_obj[key]))\n",
    "            except:\n",
    "                pass\n",
    "    # Generic values fallback\n",
    "    if len(triples) < 3:\n",
    "        for v in order_obj.values():\n",
    "            if isinstance(v, (list, str)):\n",
    "                try:\n",
    "                    li = parse_ingredient_list(v)\n",
    "                    if len(li) == 3:\n",
    "                        triples.append(li)\n",
    "                except:\n",
    "                    pass\n",
    "    # Clean to 3 triples\n",
    "    clean = []\n",
    "    for t in triples:\n",
    "        if isinstance(t, list) and len(t) == 3:\n",
    "            clean.append([float(t[0]), float(t[1]), float(t[2])])\n",
    "            if len(clean) == 3:\n",
    "                break\n",
    "    return clean\n",
    "\n",
    "def get_order_with_retry(max_fetches: int = 8, short_delay: float = 0.8):\n",
    "    for attempt in range(1, max_fetches + 1):\n",
    "        data = api_get(\"/order\", timeout=6)\n",
    "        order = data.get(\"order\", {})\n",
    "        token = data.get(\"token\", None)\n",
    "        triples = extract_triples(order)\n",
    "        if token and len(triples) == 3:\n",
    "            return token, triples\n",
    "        time.sleep(short_delay + random.uniform(0, 0.3))\n",
    "    raise RuntimeError(\"Could not fetch 3 ingredient lists with a valid token from /order\")\n",
    "\n",
    "# ============ Taste-test with array-first format + fallback ============\n",
    "def submit_taste_test(token: str, pandan_values: List[float]):\n",
    "    # 1) Send as JSON array (what most servers expect)\n",
    "    payload_array = {\"token\": token, \"result\": [float(x) for x in pandan_values]}\n",
    "    try:\n",
    "        return api_post(\"/taste-test\", payload_array, timeout=8)\n",
    "    except requests.HTTPError as e:\n",
    "        # Fallback: send as JSON string if server insists on string form\n",
    "        try:\n",
    "            if e.response is not None:\n",
    "                print(\"Array format failed; retrying with string. Server said:\", e.response.text)\n",
    "        except:\n",
    "            pass\n",
    "        payload_string = {\"token\": token, \"result\": json.dumps([float(x) for x in pandan_values])}\n",
    "        return api_post(\"/taste-test\", payload_string, timeout=8)\n",
    "\n",
    "# ============ Orchestration with close-to-threshold margin ============\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    print(\"== Limit Theory ML CTF: Auto Solver (fixed taste-test) ==\")\n",
    "    print(\"[Phase 1] Training ...\")\n",
    "    model, X, y = train_model()\n",
    "    print(f\"[Done] degree={model.degree}, R^2={model.r2:.6f}, samples={len(X)}\")\n",
    "    for i in np.random.choice(len(X), size=min(4, len(X)), replace=False):\n",
    "        yh = float(model.pipeline.predict(X[i].reshape(1, -1))[0])\n",
    "        print(f\"  sanity: true T={y[i]:.1f}, pred={yh:.1f}, c,e,s={X[i]}\")\n",
    "\n",
    "    print(\"\\n[Phase 2] Fetch order with validation ...\")\n",
    "    token, triples = get_order_with_retry(max_fetches=8, short_delay=0.8)\n",
    "    print(f\"[Prod] Got token and {len(triples)} triples.\")\n",
    "    for i, (c, e, s) in enumerate(triples):\n",
    "        print(f\"  Triple {i}: c={c:.2f}, e={e:.2f}, s={s:.2f}\")\n",
    "\n",
    "    # Small margin to stay within tolerance (close to threshold)\n",
    "    safety_frac = 0.0002   # 0.3% below threshold\n",
    "    min_abs_margin = 1.0  # at least 3 units\n",
    "    preds = []\n",
    "    for (c, e, s) in triples:\n",
    "        t_hat = float(model.pipeline.predict(np.array([[c, e, s]]))[0])\n",
    "        t_hat = max(t_hat, 0.0)\n",
    "        margin = max(min_abs_margin, safety_frac * t_hat)\n",
    "        final_value = max(t_hat - margin, 0.0)\n",
    "        preds.append(round(final_value, 3))\n",
    "        print(f\"  Pred T={t_hat:.2f}  -> submit {final_value:.2f}\")\n",
    "\n",
    "    print(f\"[Prod] Submitting taste-test pandan: {preds}\")\n",
    "    resp = submit_taste_test(token, preds)\n",
    "    print(\"[Prod] Taste-test response:\", resp)\n",
    "    if \"FLAG\" in resp:\n",
    "        print(\"\\n========== FLAG ==========\")\n",
    "        print(resp[\"FLAG\"])\n",
    "        print(\"==========================\\n\")\n",
    "    else:\n",
    "        print(\"No flag in response. Message:\", resp)\n",
    "\n",
    "    print(f\"All done in {time.time() - t0:.1f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
